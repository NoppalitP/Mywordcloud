{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "\n",
    "import whisper\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "\n",
    "import time\n",
    "from pythainlp import word_tokenize\n",
    "import pythainlp\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from rembg import remove\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import easyocr\n",
    "import cv2\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "en2th_spm = TransformerModel.from_pretrained(\n",
    "    model_name_or_path='mt/SCB_1M+TBASE_en-th_spm-spm_32000-joined_v1.0/models/',\n",
    "    checkpoint_file='checkpoint.pt',\n",
    "    data_name_or_path='mt/SCB_1M+TBASE_en-th_spm-spm_32000-joined_v1.0/vocab/',\n",
    "    bpe='sentencepiece',\n",
    "    sentencepiece_model='mt/SCB_1M+TBASE_en-th_spm-spm_32000-joined_v1.0/bpe/spm.en.model'\n",
    ")\n",
    "\n",
    "        \n",
    "    \n",
    "class MYWordcloud:\n",
    "    \n",
    "    en2th_spm = TransformerModel.from_pretrained(\n",
    "    model_name_or_path='mt/SCB_1M+TBASE_en-th_spm-spm_32000-joined_v1.0/models/',\n",
    "    checkpoint_file='checkpoint.pt',\n",
    "    data_name_or_path='mt/SCB_1M+TBASE_en-th_spm-spm_32000-joined_v1.0/vocab/',\n",
    "    bpe='sentencepiece',\n",
    "    sentencepiece_model='mt/SCB_1M+TBASE_en-th_spm-spm_32000-joined_v1.0/bpe/spm.en.model'\n",
    "    )\n",
    "    \n",
    "    def __init__(self,url: str,whisper_modelsize = \"medium\",namepath =\"video.mp4\") -> None:\n",
    "        self.url = url\n",
    "        self.namepath = namepath\n",
    "        self.download_video(self.url,self.namepath)\n",
    "        self.whisper_modelsize = whisper_modelsize\n",
    "        self.transcribe, self.language = self.transcribe_audio(self.namepath,self.whisper_modelsize)\n",
    "        self.en_text_fromaudio = self.transcribe[\"text\"]\n",
    "        \n",
    "        text = \"\"\n",
    "        for i in range(len(self.transcribe[\"segments\"])):\n",
    "            text += self.translate(self.transcribe[\"segments\"][i][\"text\"])\n",
    "        self.th_text_fromaudio = text\n",
    "        \n",
    "        self.data_fromvideo = self.open_video(self.namepath)\n",
    "        \n",
    "    @staticmethod\n",
    "    def download_video(url,namepath):\n",
    "    command = [\n",
    "        \"yt-dlp\",  \n",
    "        \"-f\", \"mp4\",\n",
    "        \"-o\",namepath, \n",
    "        url,  \n",
    "        ]\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Download video completed \")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def transcribe_audio(namepath,whisper_modelsize=\"small\"):\n",
    "        model = whisper.load_model(whisper_modelsize)\n",
    "        audio = whisper.load_audio(namepath)\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "\n",
    "        _, probs = model.detect_language(mel)\n",
    "        language = max(probs, key=probs.get)\n",
    "        if language != \"en\":\n",
    "            sentence = model.transcribe(namepath, language=\"en\", task=\"translate\")\n",
    "        else:\n",
    "            sentence = model.transcribe(namepath)\n",
    "        return (sentence ,language)\n",
    "        \n",
    "    @staticmethod\n",
    "    def translate(input_sentence):\n",
    "        return en2th_spm.translate(input_sentence)\n",
    "        \n",
    "    @staticmethod\n",
    "    def show_thumbnail(url,bw=False):\n",
    "        #เอา youtube id\n",
    "        match = re.search(r'v=([^&]+)', url)\n",
    "        if match:\n",
    "            youtube_id =  match.group(1)\n",
    "            \n",
    "        thumbnail_url = f'https://img.youtube.com/vi/{youtube_id}/maxresdefault.jpg'\n",
    "        #เขียนไฟล์จ้า\n",
    "        im_namefile = \"thumbnail.jpg\"\n",
    "        response = requests.get(thumbnail_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(im_namefile, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                print(\"ดาวน์โหลดรูปปกเสร็จเรียบร้อยแล้ว!\")\n",
    "        else:\n",
    "                print(\"ไม่สามารถดาวน์โหลดรูปปกได้\")\n",
    "        \n",
    "        mask_img = Image.open(im_namefile).convert(\"RGBA\")\n",
    "\n",
    "        if bw == False:\n",
    "            return mask_img\n",
    "        else:\n",
    "            mask_img = Image.open(im_namefile).convert(\"RGBA\")\n",
    "            mask_img = remove(mask_img)\n",
    "            mask_img.getpixel((0,0))\n",
    "            x,y = mask_img.size\n",
    "            for i in range(x):\n",
    "                for j in range(y):\n",
    "                    if mask_img.getpixel((i,j))[3] == 0:\n",
    "                        mask_img.putpixel((i,j),(255,255,255,255))\n",
    "                    else:\n",
    "                        mask_img.putpixel((i,j),(0,0,0,0))\n",
    "            return mask_img\n",
    "        \n",
    "    @staticmethod\n",
    "    def open_video(path):\n",
    "        reader = easyocr.Reader(['en',\"th\"])  \n",
    "        video_capture = cv2.VideoCapture(path)\n",
    "\n",
    "        text_data  = []\n",
    "        frame_data = []\n",
    "        while video_capture.isOpened():\n",
    "            ret, frame = video_capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "        \n",
    "            current_frame = int(video_capture.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            if current_frame % 2 != 0:\n",
    "                continue\n",
    "            \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            results = reader.readtext(gray)\n",
    "            #results = reader.readtext(frame)\n",
    "            for (bbox, text, prob) in results:\n",
    "                text = text.lower().strip().replace(\" \", \"\")\n",
    "                (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "                x1 , y1= top_left\n",
    "                x2 , y2 = bottom_right\n",
    "                \n",
    "                cv2.rectangle(frame, (int(x1),int(y1)), (int(x2),int(y2)), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{text}:{round(prob,3)}\", (int(x1),int(y1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                \n",
    "                if prob > 0.30 and all(text != item[0] for item in text_data):\n",
    "                    text_data.append([text,MYWordcloud.translate(text) ,1])\n",
    "                    frame_data.append([[current_frame], [frame]])\n",
    "                else:\n",
    "                    for i in range(0, len(text_data)):\n",
    "                        if text_data[i][0] == text:\n",
    "                            text_data[i][2] += 1\n",
    "                            frame_data[i][0].append(current_frame)\n",
    "                            frame_data[i][1].append(frame)\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        tu = []\n",
    "        for i in range(0, len(text_data)):\n",
    "            tu.append([text_data[i][1],frame_data[i][1]])\n",
    "        return tu\n",
    "    \n",
    "    def lyrics(self):\n",
    "        for i in range(len(self.transcribe[\"segments\"])):\n",
    "            print(self.transcribe[\"segments\"][i][\"text\"])\n",
    "            sleep_time = self.transcribe[\"segments\"][i][\"end\"] - self.transcribe[\"segments\"][i][\"start\"]\n",
    "            time.sleep(sleep_time)\n",
    "    \n",
    "    def detect(self, text):\n",
    "        for i in range(len(self.data_fromvideo)):\n",
    "            if text == self.data_fromvideo[i][0]:\n",
    "                frames = self.data_fromvideo[i][1]\n",
    "                num_frames = len(frames)\n",
    "                break\n",
    "        else:\n",
    "            print(f\"No data found for text: {text}\")\n",
    "            return\n",
    "\n",
    "        grid_size = math.ceil(math.sqrt(num_frames))\n",
    "\n",
    "        fig, axs = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "        axs = np.atleast_1d(axs).flatten()\n",
    "\n",
    "        for i in range(num_frames):\n",
    "            axs[i].imshow(frames[i])\n",
    "            axs[i].axis(\"off\")\n",
    "\n",
    "        for j in range(num_frames, grid_size * grid_size):\n",
    "            axs[j].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def show(self, mask=True):\n",
    "        wc_list = []\n",
    "        list_word = word_tokenize(self.th_text_fromaudio)  \n",
    "        text1 = \" \".join(list_word).lower().strip()  \n",
    "        text2 = \"\"\n",
    "        \n",
    "        for st in self.data_fromvideo:\n",
    "            for i in range(len(st)):  \n",
    "                text2 += st[0].replace(\" \", \"\") + \" \"\n",
    "        \n",
    "        text_list = [text1, text2]\n",
    "        \n",
    "        for text in text_list:\n",
    "            if mask:\n",
    "                mask_img = np.array(self.show_thumbnail(self.url, bw=True))  \n",
    "                wc_list.append(WordCloud(\n",
    "                    font_path=\"D:\\summer\\opas v.2\\THSarabunNew.ttf\",\n",
    "                    regexp=\"[ก-๙]+\",\n",
    "                    width=2000, height=1000,\n",
    "                    prefer_horizontal=1,\n",
    "                    stopwords=set(pythainlp.corpus.thai_stopwords()),\n",
    "                    max_words=50,\n",
    "                    colormap=\"viridis\",\n",
    "                    background_color=\"white\",\n",
    "                    mask=mask_img).generate(text))\n",
    "            else:\n",
    "                wc_list.append(WordCloud(\n",
    "                    font_path=\"D:\\summer\\opas v.2\\THSarabunNew.ttf\",\n",
    "                    regexp=\"[ก-๙]+\",\n",
    "                    width=2000, height=1000,\n",
    "                    prefer_horizontal=1,\n",
    "                    stopwords=set(pythainlp.corpus.thai_stopwords()),\n",
    "                    max_words=50,\n",
    "                    colormap=\"viridis\",\n",
    "                    background_color=\"white\").generate(text))\n",
    "\n",
    "\n",
    "        if len(wc_list) >= 2:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(15,15))\n",
    "            ax[0].imshow(wc_list[0])\n",
    "            ax[0].axis(\"off\")\n",
    "            ax[0].set_title(\"Audio\")\n",
    "            ax[1].imshow(wc_list[1])\n",
    "            ax[1].axis(\"off\")\n",
    "            ax[1].set_title(\"Video\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Not enough word clouds generated to display.\")\n",
    "\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
